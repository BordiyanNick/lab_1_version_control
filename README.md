# –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –≤–∏–∂–∏–≤–∞–Ω–Ω—è –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤ ‚Äî *Haberman Survival Dataset*

## –û–ø–∏—Å –ø—Ä–æ—î–∫—Ç—É
–¶–µ–π –ø—Ä–æ—î–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä—É—î –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–µ—Ç–æ–¥—ñ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è ‚Äî **–ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó** —Ç–∞ **–º–µ—Ç–æ–¥—É –æ–ø–æ—Ä–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ (SVM)** ‚Äî –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –≤–∏–∂–∏–≤–∞–Ω–Ω—è –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤ –ø—ñ—Å–ª—è –æ–ø–µ—Ä–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞–Ω–∏—Ö —ñ–∑ **Haberman Survival Dataset**.

–ú–µ—Ç–∞ –ø—Ä–æ—î–∫—Ç—É ‚Äî –¥–æ—Å–ª—ñ–¥–∏—Ç–∏, —è–∫ —Ä—ñ–∑–Ω—ñ –º–æ–¥–µ–ª—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–∂—É—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ª—ñ–∫—É–≤–∞–Ω–Ω—è –ø–∞—Ü—ñ—î–Ω—Ç–∞ –∑–∞ —Ç–∞–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
- **Age** ‚Äî –≤—ñ–∫ –ø–∞—Ü—ñ—î–Ω—Ç–∞;
- **Year** ‚Äî —Ä—ñ–∫ –æ–ø–µ—Ä–∞—Ü—ñ—ó;
- **Nodes** ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å —É—Ä–∞–∂–µ–Ω–∏—Ö –ª—ñ–º—Ñ–∞—Ç–∏—á–Ω–∏—Ö –≤—É–∑–ª—ñ–≤.

---

## –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏
–ü—Ä–æ—î–∫—Ç —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –º–æ–≤–æ—é **Python** –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ç–∞–∫–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫:

- `pandas` ‚Äî –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö;
- `numpy` ‚Äî —á–∏—Å–µ–ª—å–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è;
- `matplotlib` ‚Äî –ø–æ–±—É–¥–æ–≤–∞ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤;
- `scikit-learn` ‚Äî –º–æ–¥–µ–ª—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è (Logistic Regression, SVM, –º–µ—Ç—Ä–∏–∫–∏, –ø–æ–¥—ñ–ª –≤–∏–±—ñ—Ä–∫–∏).

---

## –û—Å–Ω–æ–≤–Ω—ñ –µ—Ç–∞–ø–∏ —Ä–æ–±–æ—Ç–∏

### 1Ô∏è‚É£ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

url = 'https://raw.githubusercontent.com/rikhuijzer/haberman-survival-dataset/main/haberman.csv'
data = pd.read_csv(url)

data.columns = ['Age', 'Year', 'Nodes', 'Survival']
data['Survival'] = data['Survival'].apply(lambda x: 1 if x == 1 else 0)


### 2Ô∏è‚É£ –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤–∏–±—ñ—Ä–∫–∏
X = data[['Age', 'Nodes']]
y = data['Survival']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


### 3Ô∏è‚É£ –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è
log_model = LogisticRegression()
log_model.fit(X_train, y_train)

y_pred_log = log_model.predict(X_test)

print("–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è")
print("–¢–æ—á–Ω—ñ—Å—Ç—å (Accuracy):", accuracy_score(y_test, y_pred_log))
print("–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏:\n", confusion_matrix(y_test, y_pred_log))
print("–ó–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:\n", classification_report(y_test, y_pred_log))

### 4Ô∏è‚É£ –ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ (SVM)
svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)

y_pred_svm = svm_model.predict(X_test)

print("SVM")
print("–¢–æ—á–Ω—ñ—Å—Ç—å (Accuracy):", accuracy_score(y_test, y_pred_svm))
print("–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏:\n", confusion_matrix(y_test, y_pred_svm))
print("–ó–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:\n", classification_report(y_test, y_pred_svm))


### 5Ô∏è‚É£ –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –Ω–æ–≤–∏—Ö –æ–±‚Äô—î–∫—Ç—ñ–≤
new_objects = np.array([
[45, 0],
[60, 5],
[70, 20],
[30, 1],
[55, 3]
])

log_preds_new = log_model.predict(new_objects)
svm_preds_new = svm_model.predict(new_objects)

print("–ü—Ä–æ–≥–Ω–æ–∑–∏ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó:", log_preds_new)
print("–ü—Ä–æ–≥–Ω–æ–∑–∏ SVM:", svm_preds_new)


### 6Ô∏è‚É£ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X_test['Age'], X_test['Nodes'], c=y_test, cmap='bwr', alpha=0.6, label='–¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ')
plt.scatter(new_objects[:, 0], new_objects[:, 1], c='green', marker='x', s=100, label='–ù–æ–≤—ñ –æ–±‚Äô—î–∫—Ç–∏')
plt.title("Logistic Regression")
plt.xlabel("Age")
plt.ylabel("Nodes")
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(X_test['Age'], X_test['Nodes'], c=y_test, cmap='bwr', alpha=0.6, label='–¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ')
plt.scatter(new_objects[:, 0], new_objects[:, 1], c='green', marker='x', s=100, label='–ù–æ–≤—ñ –æ–±‚Äô—î–∫—Ç–∏')
plt.title("SVM")
plt.xlabel("Age")
plt.ylabel("Nodes")
plt.legend()

plt.tight_layout()
plt.show()


### 7Ô∏è‚É£ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
results = pd.DataFrame({
'Age': new_objects[:, 0],
'Nodes': new_objects[:, 1],
'Logistic Regression': log_preds_new,
'SVM': svm_preds_new
})
print(results)


–ö–æ–∂–Ω–∞ —Ç–æ—á–∫–∞ –Ω–∞ –≥—Ä–∞—Ñ—ñ–∫—É –ø–æ–∑–Ω–∞—á–∞—î –ø–∞—Ü—ñ—î–Ω—Ç–∞:

- üü¢ ‚Äî –≤–∏–∂–∏–≤ (1)  
- üî¥ ‚Äî –Ω–µ –≤–∏–∂–∏–≤ (0)  
- ‚ùå ‚Äî –Ω–æ–≤—ñ –æ–±‚Äô—î–∫—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó

---
